# OH-Sentence Dataset

## Introduction
---
OH-Sentence is a large-scale continuous sign language recognition (SLR) dataset including sEMG and IMU modalities. 723 sentences with 1,176 sign language words are selected from daily conversation textbooks for the hearing impaired. 24 participants (11 men and 13 women) are invited to collect the OH-Sentence dataset, including 4 sign language experts, 13 hearing-impaired people (students, employees, etc.), and 7 able-bodied people with professional training. During the data collection phase, each participant is asked to wear an armband on their right hand and performs each sentence five times.

## Download
---
The OH-Sentence database is released to universities and research institutes for research purpose only. To request the access right to the data resources, please follow the instructions below:
- Download the [OH-Sentence Dataset Release Agreement](https://github.com/ZhangJiangtao-0108/OH-Sentence_Dataset/blob/main/OH-Sentence%20_Dataset%20_Release%20_Agreement.pdf);
- Read all items and conditions carefully;
- Complete it appropriately. Note that the agreement should be signed by a full-time staff member (that is, the student is not acceptable).
- Please scan the signed agreement, send it to (zhangjiangtao@mail.hfut.edu.cn) and CC to Prof. Wang (qswang@hfut.edu.cn). If you are a student, please also CC to the full-time staff member who sign the agreement.

## Reference
---
Please cite the following papers if you use OH-Sentence dataset for your research:
- J. Zhang, Q. Wang, Q. Wang, and Z. Zheng, “Multimodal fusion framework based on statistical attention and contrastive attention for sign language recognition,” IEEE Transactions on Mobile Computing, vol. 23, no. 2, pp. 1431-1443, 2024.
  
Besides, you can refer to the following papers for continuous SLR published by our group:
- J. Zhang, Q. Wang, and Q. Wang, “HDTSLR: A framework based on hierarchical dynamic positional encoding for sign language recognition,” IEEE Transactions on Mobile Computing, vol. 23, no. 5, pp. 5631-5643，2024.
- J. Zhang, Q. Wang, and Q. Wang, “A Sign Language Recognition Framework Based on Cross-Modal Complementary Information Fusion,” IEEE Transactions on Multimedia, pp. 1–13, 2024, doi:10.1109/TMM.2024.3377095.
- J. Zhang, Q. Wang, and Q. Wang, “U-Shaped Distribution Guided Sign Language Emotion Recognition With Semantic and Movement Features,” IEEE Transactions on Affective Computing, pp. 1–13, 2023, doi:10.1109/TMC.2023.3310712

## Contact
If you have any questions about the dataset and our papers, please feel free to contact us:
- Qingshan wang, Professor, HFUT, qswang@hfut.edu.cn
- Jiangtao Zhang, Ph.D Student, HFUT, zhangjiangtao@mail.hfut.edu.cn
